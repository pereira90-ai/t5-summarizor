{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hundred-allen",
   "metadata": {},
   "source": [
    "# Model Pipeline Preparation\n",
    "\n",
    "This Jupyter Notebook demonstrates how a pre-trained model is loaded and used to generate summary.\n",
    "\n",
    "New column will be created in database to store the generated summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-blair",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "correct-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from summarizer import Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-occasion",
   "metadata": {},
   "source": [
    "## Load data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "requested-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pdf/Maple Knoll Communities success story.pdf</td>\n",
       "      <td>Residents  \\nfirst, technology \\nsecond\\n\\nSUC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pdf/circle-of-life-hospice.pdf</td>\n",
       "      <td>Committed  \\nto providing  \\ncompassionate \\nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pdf/Concord Regional VNA Systems Success Story...</td>\n",
       "      <td>EHR software \\ndelivers increased \\nproductivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pdf/willow-health.pdf</td>\n",
       "      <td>Overcoming  \\nEHR adoption \\nhurdles\\n\\nSUCCES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pdf/first-choice-home-health-and-hospice.pdf</td>\n",
       "      <td>Eliminating paper \\nand improving \\norganizati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  \\\n",
       "0      pdf/Maple Knoll Communities success story.pdf   \n",
       "1                     pdf/circle-of-life-hospice.pdf   \n",
       "2  pdf/Concord Regional VNA Systems Success Story...   \n",
       "3                              pdf/willow-health.pdf   \n",
       "4       pdf/first-choice-home-health-and-hospice.pdf   \n",
       "\n",
       "                                            raw_text  \n",
       "0  Residents  \\nfirst, technology \\nsecond\\n\\nSUC...  \n",
       "1  Committed  \\nto providing  \\ncompassionate \\nc...  \n",
       "2  EHR software \\ndelivers increased \\nproductivi...  \n",
       "3  Overcoming  \\nEHR adoption \\nhurdles\\n\\nSUCCES...  \n",
       "4  Eliminating paper \\nand improving \\norganizati...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../data/Text.db')\n",
    "df = pd.read_sql_table('Text_table', engine)\n",
    "\n",
    "# display loaded dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-system",
   "metadata": {},
   "source": [
    "## Load pre-train model and model tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "immediate-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-train model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n",
    "\n",
    "# load model tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weekly-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for generating summary\n",
    "\n",
    "def ext_sum(text, ratio=0.8):\n",
    "    \"\"\"\n",
    "    Generate extractive summary using BERT model\n",
    "    \n",
    "    INPUT:\n",
    "    text - str. Input text\n",
    "    ratio - float. Enter a ratio between 0.1 - 1.0 [default = 0.8]\n",
    "            (ratio = summary length / original text length)\n",
    "    \n",
    "    OUTPUT:\n",
    "    summary - str. Generated summary\n",
    "    \"\"\"\n",
    "    bert_model = Summarizer()\n",
    "    summary = bert_model(text, ratio=ratio)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def abs_sum(text, model, tokenizer, min_length=80, \n",
    "                     max_length=150, length_penalty=15, \n",
    "                     num_beams=2):\n",
    "    \"\"\"\n",
    "    Generate abstractive summary using T5 model\n",
    "    \n",
    "    INPUT:\n",
    "    text - str. Input text\n",
    "    model - model name\n",
    "    tokenizer - model tokenizer\n",
    "    min_length - int. The min length of the sequence to be generated\n",
    "                      [default = 80]\n",
    "    max_length - int. The max length of the sequence to be generated \n",
    "                      [default = 150]\n",
    "    length_penalty - float. Set to values < 1.0 in order to encourage the model \n",
    "                     to generate shorter sequences, to a value > 1.0 in order to \n",
    "                     encourage the model to produce longer sequences.\n",
    "                     [default = 15]\n",
    "    num_beams - int. Number of beams for beam search. 1 means no beam search\n",
    "                     [default = 2]\n",
    "    \n",
    "    OUTPUT:\n",
    "    summary - str. Generated summary\n",
    "    \"\"\"\n",
    "    tokens_input = tokenizer.encode(\"summarize: \"+text, return_tensors='pt', \n",
    "                                    # model tokens max input length\n",
    "                                    max_length=tokenizer.model_max_length, \n",
    "                                    truncation=True)\n",
    "    \n",
    "    summary_ids = model.generate(tokens_input,\n",
    "                                min_length=min_length,\n",
    "                                max_length=max_length,\n",
    "                                length_penalty=length_penalty, \n",
    "                                num_beams=num_beams)\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "    return summary\n",
    "\n",
    "def generate_summary(text, model, tokenizer, ext_ratio=1.0, min_length=80, \n",
    "                     max_length=150, length_penalty=15, \n",
    "                     num_beams=2):\n",
    "    \"\"\"\n",
    "    Generate summary for using extractive & abstractive methods\n",
    "    \n",
    "    INPUT:\n",
    "    text - str. Input text\n",
    "    model - model name\n",
    "    tokenizer - model tokenizer\n",
    "    ext_ratio - float. Enter a ratio between 0.1 - 1.0 [default = 1.0]\n",
    "                (ratio = summary length / original text length)\n",
    "                1.0 means no extractive summarization is performed before \n",
    "                abstractive summarization\n",
    "    min_length - int. The min length of the sequence to be generated\n",
    "                 [default = 80]\n",
    "    max_length - int. The max length of the sequence to be generated \n",
    "                 [default = 150]\n",
    "    length_penalty - float. Set to values < 1.0 in order to encourage the model \n",
    "                     to generate shorter sequences, to a value > 1.0 in order to \n",
    "                     encourage the model to produce longer sequences.\n",
    "                     [default = 15]\n",
    "    num_beams - int. Number of beams for beam search. 1 means no beam search\n",
    "                     [default = 2]\n",
    "    \n",
    "    OUTPUT:\n",
    "    summary - str. Generated summary\n",
    "    \"\"\"\n",
    "    if ext_ratio == 1.0:\n",
    "        summary = abs_sum(text, model, tokenizer, min_length, \n",
    "                       max_length, length_penalty, num_beams)\n",
    "    elif ext_ratio < 1.0:\n",
    "        text = ext_sum(text, ratio = ext_ratio)\n",
    "        summary = abs_sum(text, model, tokenizer, min_length, \n",
    "                       max_length, length_penalty, num_beams)\n",
    "    else:\n",
    "        print('Error! Please enter ext_ratio betwen 0.1 and 1.0')\n",
    "        \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powered-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate summary and save output to list and text file\n",
    "\n",
    "# please be patience, as this loop will take some time to run\n",
    "\n",
    "def gen_sum_save_monitor(df, model, tokenizer, output_folder, ext_ratio=1.0, \n",
    "                         min_length=80, max_length=150, length_penalty=15, \n",
    "                         num_beams=2):\n",
    "    \"\"\"\n",
    "    Monitor progress while generating summary & save output to list & text file\n",
    "    \n",
    "    INPUT:\n",
    "    df - DataFrama. Data loaded from database\n",
    "    model - model name\n",
    "    tokenizer - model tokenizer\n",
    "    output_folder - str. Folder name to save the generated output in text file\n",
    "    ext_ratio - float. Enter a ratio between 0.1 - 1.0 [default = 1.0]\n",
    "                (ratio = summary length / original text length)\n",
    "                1.0 means no extractive summarization is performed before \n",
    "                abstractive summarization\n",
    "    min_length - int. The min length of the sequence to be generated\n",
    "                 [default = 80]\n",
    "    max_length - int. The max length of the sequence to be generated\n",
    "                 [default = 150]\n",
    "    length_penalty - float. Set to values < 1.0 in order to encourage the model \n",
    "                     to generate shorter sequences, to a value > 1.0 in order to \n",
    "                     encourage the model to produce longer sequences.\n",
    "                     [default = 15]\n",
    "    num_beams - int. Number of beams for beam search. 1 means no beam search \n",
    "                [default = 2]\n",
    "    \n",
    "    OUTPUT:\n",
    "    summaries - list. Generated summary appended to a list\n",
    "    \"\"\"\n",
    "    # create an empty list\n",
    "    summaries = []\n",
    "    # loop through each raw_text row in dataset, generate summary, \n",
    "    # append summary to summaries list\n",
    "    for i in range(len(df)):\n",
    "        file_path = df.file_path[i]\n",
    "        raw_text = df.raw_text[i]\n",
    "    \n",
    "        start = time.time()\n",
    "        summary = generate_summary(raw_text, model, tokenizer, \n",
    "                                   ext_ratio, min_length, max_length, \n",
    "                                   length_penalty, num_beams)\n",
    "        \n",
    "        file_name = file_path[4:][:-4]+'_summary.txt'\n",
    "        \n",
    "        with open(output_folder + \"/\" + file_name, 'w')as text_file:\n",
    "            text_file.write(summary)\n",
    "        \n",
    "        \n",
    "        summaries.append(summary)\n",
    "        end = time.time()\n",
    "        print(\" Summarized '{}'[time: {:.2f}s]\".format(file_path, \n",
    "                                                       end-start))\n",
    "        \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seasonal-newport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summarized 'pdf/Maple Knoll Communities success story.pdf'[time: 21.20s]\n",
      " Summarized 'pdf/circle-of-life-hospice.pdf'[time: 21.27s]\n",
      " Summarized 'pdf/Concord Regional VNA Systems Success Story.pdf'[time: 21.09s]\n",
      " Summarized 'pdf/willow-health.pdf'[time: 21.45s]\n",
      " Summarized 'pdf/first-choice-home-health-and-hospice.pdf'[time: 19.47s]\n"
     ]
    }
   ],
   "source": [
    "summaries = gen_sum_save_monitor(df, model, tokenizer, '../data/output', ext_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spare-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new 'summary' column and append to df\n",
    "df['summary'] = summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tracked-saturn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pdf/Maple Knoll Communities success story.pdf</td>\n",
       "      <td>Residents  \\nfirst, technology \\nsecond\\n\\nSUC...</td>\n",
       "      <td>Maple Knoll Communities has been delivering ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pdf/circle-of-life-hospice.pdf</td>\n",
       "      <td>Committed  \\nto providing  \\ncompassionate \\nc...</td>\n",
       "      <td>Circle of Life Hospice is the largest non-prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pdf/Concord Regional VNA Systems Success Story...</td>\n",
       "      <td>EHR software \\ndelivers increased \\nproductivi...</td>\n",
       "      <td>a Concord regional VNA (CRVNA) in central new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pdf/willow-health.pdf</td>\n",
       "      <td>Overcoming  \\nEHR adoption \\nhurdles\\n\\nSUCCES...</td>\n",
       "      <td>Netsmart EHR delivered a fully-integrated sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pdf/first-choice-home-health-and-hospice.pdf</td>\n",
       "      <td>Eliminating paper \\nand improving \\norganizati...</td>\n",
       "      <td>first choice home health and hospice was clear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  \\\n",
       "0      pdf/Maple Knoll Communities success story.pdf   \n",
       "1                     pdf/circle-of-life-hospice.pdf   \n",
       "2  pdf/Concord Regional VNA Systems Success Story...   \n",
       "3                              pdf/willow-health.pdf   \n",
       "4       pdf/first-choice-home-health-and-hospice.pdf   \n",
       "\n",
       "                                            raw_text  \\\n",
       "0  Residents  \\nfirst, technology \\nsecond\\n\\nSUC...   \n",
       "1  Committed  \\nto providing  \\ncompassionate \\nc...   \n",
       "2  EHR software \\ndelivers increased \\nproductivi...   \n",
       "3  Overcoming  \\nEHR adoption \\nhurdles\\n\\nSUCCES...   \n",
       "4  Eliminating paper \\nand improving \\norganizati...   \n",
       "\n",
       "                                             summary  \n",
       "0  Maple Knoll Communities has been delivering ca...  \n",
       "1  Circle of Life Hospice is the largest non-prof...  \n",
       "2  a Concord regional VNA (CRVNA) in central new ...  \n",
       "3  Netsmart EHR delivered a fully-integrated sing...  \n",
       "4  first choice home health and hospice was clear...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "isolated-pickup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: pdf/Maple Knoll Communities success story.pdf\n",
      "\n",
      "Summary:\n",
      "---------\n",
      "Maple Knoll Communities has been delivering care for over 172 years. the organization is by no means encumbered by processes of the past. Maple Knoll believes in the power of innovation and that technology can, and does, make life easier for residents, staff and families. with Netsmart Telehealth, Maple Knoll can improve clinical satisfaction. with virtual visits and improve physician. & resident satisfaction. the organization has been delivering care for over 172 years, the organization is by no means \n",
      "\n",
      "\n",
      "File path: pdf/circle-of-life-hospice.pdf\n",
      "\n",
      "Summary:\n",
      "---------\n",
      "Circle of Life Hospice is the largest non-profit hospice in northwest Arkansas. Circle of Life is committed to compassionate end-of-life care for a person’s body, mind, spirit and family when there is no longer a cure. the hospital readmission rate for patients admitted to Circle of Life in 2017 was 0.5 percent. the organization’s core values of compassion, inclusion, respect, comfort, leadership and excellence make Circle of Life a community of quality care when it matters most. the hospice advisor solution was a\n",
      "\n",
      "\n",
      "File path: pdf/Concord Regional VNA Systems Success Story.pdf\n",
      "\n",
      "Summary:\n",
      "---------\n",
      "a Concord regional VNA (CRVNA) in central new hampshire has 378 staff members offering home care, hospice, palliative care. the referral process accounts for a significant portion of a homecare organization’s business— 100 percent to be exact. referring agencies and especially referring physicians must:  Understand the agency’s strengths and capabilities  Have confidence in the level of care their patients will receive.  Establish efficient communication and data exchange methods that enable and facilitate future care plan\n",
      "\n",
      "\n",
      "File path: pdf/willow-health.pdf\n",
      "\n",
      "Summary:\n",
      "---------\n",
      "Netsmart EHR delivered a fully-integrated single patient record that unifies clinical, financial and census data across the full continuum of care. the solution was selected for its ability to deliver a fully-integrated single patient record that unifies clinical, financial and census data across the full continuum of care. 'it is well worth the money to spend time with the experts at Netsmart to review what we use, how we use it, and how we can do better,' says Shelly Miller chief\n",
      "\n",
      "\n",
      "File path: pdf/first-choice-home-health-and-hospice.pdf\n",
      "\n",
      "Summary:\n",
      "---------\n",
      "first choice home health and hospice was clear about its need for a fully electronic homecare and hospice solution. \"we wanted an innovator—someone who would always push forward,\" said Beau Sorensen, chief financial officer. \"we're seeing a 17 percent increase in clinician productivity,\" said Sorensen. \"it's a great time to be a part of a company that is transforming itself,\" said sorensen.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the generated summary\n",
    "for i in range(len(df)):\n",
    "    print(\"File path: {}\".format(df.file_path[i]))\n",
    "    print(\"\")\n",
    "    print('Summary:')\n",
    "    print(\"---------\")\n",
    "    print(df.summary[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "centered-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save summary to SQLite database\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///../data/Text.db')\n",
    "df.to_sql('Text_table', engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
